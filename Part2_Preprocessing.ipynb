{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56ca206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import text \n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a21654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech=pd.read_csv('obamaspeech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868ef328",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_file=open('stopwords_file.txt', 'r')\n",
    "words=stop_word_file.read()\n",
    "\n",
    "additional= ['from', 'subject', 'barack','hussein','obama','use','say','like','just','dont','don','im','it','ve','re','we',\n",
    "                'live','youll','youve','things','thing','youre','right','really','lot', \n",
    "                'make','know','people','way','day', 'little', 'maybe','men',\"americans\",\"america\",\"american\",'beverybrief','michelleand','president','united',\"states\", \"s\", \"u\",\"evening\", \"afternoon\", \"welcome\",\n",
    "               \"everybody\", \"goodbye\", 'want', 'take', 'see', 'say', 'go','like','youre','ive','im','really','id','just','dont','didnt','thi','wa',\n",
    "                  'say','know','make','people',\"today\",'way','day','time','year','tonight', 'u', 'country','mr','melhem','tim']      \n",
    "\n",
    "stop_words=words.split(\",\")+additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542824c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "        # Remove the punctuations\n",
    "        text=re.sub('-', ' ', text)\n",
    "        text=contractions.fix(text)\n",
    "        text=re.sub(\"'s\", ' ', text)\n",
    "        text=re.sub('\\t', ' ', text)\n",
    "        text=re.sub('\\xa0', ' ', text)\n",
    "        text=re.sub('\\r', ' ', text)\n",
    "        text=re.sub('\\n', ' ', text)\n",
    "        text=re.sub(\"[!@#$';.:]\", ' ',text)\n",
    "        text=text.lower()\n",
    "        text= re.sub('\\((.*?\\))', '', text)\n",
    "        text= re.sub('\\[.*?\\]', '', text)\n",
    "        text= re.sub('[%s]' % re.escape(string.punctuation), '',text)\n",
    "        text= re.sub('\\w*\\d\\w*', '', text)\n",
    "        text=text.lower()\n",
    "        \n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        # Remove stopword\n",
    "        tokens = [word for word in tokens if not word in stop_words]\n",
    "        # Lemmatize\n",
    "        lemma = WordNetLemmatizer()\n",
    "        tokens = [lemma.lemmatize(word, pos=\"v\") for word in tokens]\n",
    "        tokens = [lemma.lemmatize(word, pos=\"n\") for word in tokens]\n",
    "        \n",
    "        # list to string\n",
    "        text = \" \".join(tokens)\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1304cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech['clean_content']=[clean_text(i) for i in df_speech[\"content\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1b75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech.to_csv('obama_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
